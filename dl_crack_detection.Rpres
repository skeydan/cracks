<style>
.footer {
    position: fixed; 
    top: 90%;
    text-align:right; 
    width:100%;
}

.banner {
    position: fixed; 
    top: 0%;
    text-align:right; 
    width:100%;
}

.reveal section img {
  border: 0px;
  box-shadow: 0 0 0 0;
}
.reveal table td {
  border: 0px;
}

.reveal table {
  border: 0px;
}

.reveal h1 {
  font-size: 1.6em;
}

.reveal figcaption {
  font-size: 0.4em;
}

.small-code pre code {
  font-size: .85em;
}

.reveal .smalltext {
  font-size: 0.75em;
}

</style>


Automatic crack detection - with deep learning
========================================================
author: Sigrid Keydana, Trivadis
date: 2017/22/09
autosize: true
incremental:false
width: 1440


Crack? No crack?
========================================================

<table>
<tr>
<td><img src="data/test/crack/img_8_1121_1793.png"</td>
<td><img src="data/test/crack/img_8_1345_1.png"</td>
<td><img src="data/test/crack/img_10_1121_449.png"</td>
<td><img src="data/test/crack/img_10_1121_673.png"</td>
<td><img src="data/test/nocrack/img_8_1_225.png"</td>
<td><img src="data/test/nocrack/img_8_1_1793.png"</td>
</tr>
<tr>
<td><img src="data/test/crack/img_9_897_673.png"</td>
<td><img src="data/test/crack/img_9_1121_449.png"</td>
<td><img src="data/test/crack/img_9_1121_1793.png"</td>
<td><img src="data/test/crack/img_10_1121_2241.png"</td>
<td><img src="data/test/nocrack/img_9_225_449.png"</td>
<td><img src="data/test/nocrack/img_11_449_897.png"</td>
</tr>
<tr>
<td><img src="data/test/crack/img_8_1793_225.png"</td>
<td><img src="data/test/crack/img_9_2017_673.png"</td>
<td><img src="data/test/crack/img_11_1569_2689.png"</td>
<td><img src="data/test/crack/img_8_449_1.png"</td>
<td><img src="data/test/nocrack/img_11_1_1.png"</td>
<td><img src="data/test/nocrack/img_11_897_2465.png"</td>
</tr>
</table>

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>One step back: What's deep learning?</h1>



What is a neural network?
========================================================

&nbsp;

Biological neuron and artificial neuron

&nbsp;

<figure>
    <img src='neuron1.png' width='30%' align="left" style="margin-right: 10%;"/>
    <img src='neuron2.png' width='30%' align="left" style="margin-right: 30%;"/>
     <figcaption>Source: <a href='https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html'>Stergiou, C. and Siganos, D. Artificial neurons</a>
</figure>


<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>



Prototype of a neuron: the perceptron 
========================================================

<figure>
  <img src='perceptron.png' width='800px' />
<figcaption>Source: <a href='https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html'>Stergiou, C. and Siganos, D. Artificial neurons</a>
</figure>


<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>



Going deep
========================================================

<figure>
  <img src='deep_nn.png' width='800px' />
<figcaption>Source: <a href='https://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html'>Stergiou, C. and Siganos, D. Artificial neurons</a>
</figure>


<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>



Why go deep? A bit of background
========================================================
incremental:true

&nbsp;

Easy? Difficult?

- walk
- talk
- play chess
- solve matrix computations

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>




Representation matters
========================================================

<figure>
    <img src='coords.png' width='60%'/>
    <figcaption>Source: Goodfellow et al. 2016, <a href='http://www.deeplearningbook.org/'>Deep Learning</a></figcaption>
</figure>

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>



Just feed the network the right features?
========================================================

&nbsp;

What are the correct pixel values for a "bike" feature?

- race bike, mountain bike, e-bike?
- pixels in the shadow may be much darker
- what if bike is mostly obscured by rider standing in front?

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>



Let the network pick the features
========================================================

... a layer at a time

<figure>
    <img src='features.png' width='40%'/> 
    <figcaption>Source: Goodfellow et al. 2016, <a href='http://www.deeplearningbook.org/'>Deep Learning</a></figcaption>

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>



========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>How does a deep network learn?</h1>





Training a deep neural network
========================================================

&nbsp;

We need:

- a way to quantify our current (e.g., classification) error
- a way to reduce error on subsequent iterations
- a way to propagate our improvement logic from the output layer all the way back through the network!

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Quantifying error: Loss functions
========================================================

&nbsp;

The _loss_ (or _cost_) function indicates the cost incurred from false prediction / misclassification.

Probably the best-known loss functions in machine learning are __mean squared error__: 

  $\frac{1}{n} \sum_n{(\hat{y} - y)^2}$
  
and __cross entropy__ :

  $- \sum_j{t_j log(y_j)}$
  
<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Learning from errors: Gradient Descent
========================================================


<figure>
    <img src='convex.png' width='40%'/>
     <figcaption>Source: Goodfellow et al. 2016, <a href='http://www.deeplearningbook.org/'>Deep Learning</a>
</figure>

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Propagate back errors ... well: backpropagation!
========================================================

&nbsp;

- basically, just the chain rule: $\frac{dz}{dx} = \frac{dz}{dy} \frac{dy}{dx}$
- chained over several layers:

<figure>
    <img src='backprop2.png' width='40%'/>
    <figcaption>Source: <a href=https://colah.github.io/posts/2015-08-Backprop/>https://colah.github.io/posts/2015-08-Backprop/</a></figcaption>
</figure>

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

 


========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>Example domain: Convolutional Neural Networks for Computer Vision</h1>


Why computer vision is hard
========================================================

<figure>
<img src='deformable_cat.png' width='800px' />
<figcaption>Source: <a href='http://www.robots.ox.ac.uk/~vgg/publications/2012/parkhi12a/parkhi12a.pdf'>Parkhi et al. Cats and Dogs</a>
</figcaption>
</figure>

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>



Tasks in computer vision
========================================================

<figure>
<img src='class_loc_dec_seg.png' width='1000px' />
<figcaption>Source: <a href='http://cs231n.github.io/'>Stanford CS231n Convolutional Neural Networks Lecture Notes</a></figcaption>
</figure>

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Convolutional Neural Networks (CNNs)
========================================================

&nbsp;


<figure>
    <img src='convnet.jpeg' width='60%'/>
    <figcaption>Source: <a href='http://cs231n.github.io/convolutional-networks/'>http://cs231n.github.io/convolutional-networks/</a></figcaption>
</figure>

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


The Convolution Operation
========================================================

&nbsp;

<figure>
    <img src='convolution_demo.png' width='40%'/>
    <figcaption>Source: <a href='http://cs231n.github.io/convolutional-networks/'>http://cs231n.github.io/convolutional-networks/</a> (Live Demo on website!)</figcaption>
</figure>

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>
 


========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>Back to our cracks!</h1>



========================================================

&nbsp;



<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>
 
Let's build our own CNN, in Keras
========================================================

&nbsp;

4 steps
- build model
- prepare data
- train model
- test model

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Build model
========================================================
class:small-code

&nbsp;

```{r, echo=FALSE}
library(keras)
target_width <- 224
target_height <- 224
```


```{r}
model <- keras_model_sequential()

model %>%
  layer_conv_2d(
    filter = 32, kernel_size = c(3,3), padding = "same", input_shape = c(target_height, target_width, 3) ) %>%
  layer_activation("relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  
  layer_conv_2d(filter = 32, kernel_size = c(3,3)) %>%
  layer_activation("relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  
  layer_conv_2d(filter = 64, kernel_size = c(3,3), padding = "same") %>%
  layer_activation("relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  
  layer_flatten() %>%
  layer_dense(64) %>%
  layer_activation("relu") %>%
  layer_dropout(0.5) %>%
  layer_dense(2) %>%
  layer_activation("softmax")

opt <- optimizer_rmsprop(lr = 0.001, decay = 1e-6)

model %>% compile(
  loss = "binary_crossentropy",
  optimizer = opt,
  metrics = "accuracy"
)

```

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


How about the data?
========================================================
incremental:true

&nbsp;

- in this case study, we have very little data at our disposition
- can use data augmentation to artificially increase training set size

&nbsp;

```{r}
train_datagen <- image_data_generator(
    rescale = 1/255,
    rotation_range = 80,
    width_shift_range = 0.2,
    height_shift_range = 0.2,
    horizontal_flip = TRUE,
    vertical_flip = TRUE,
    shear_range = 0.2,
    zoom_range = 0.2,
    fill_mode = "wrap"
  )
```


<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>

Train model
========================================================
incremental:true

&nbsp;

- Ready to resume in a few hours?
- Let's load the trained model instead

```{r}
model_name <- "model_filter323264_kernel3_epochs20_lr001.h5"
model <- load_model_hdf5(model_name)
```


<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Test model
========================================================

&nbsp;

- Accuracy (on test set): 0.86
- Recall (on test set): 0.88
- Precision (on test set): 0.85

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Let's look at some predictions!
========================================================

&nbsp;

```{r, echo=FALSE}
library(EBImage)
img <- readImage("data/train/crack/img_1_1_1345.png")
display(img)
```

```{r, echo=FALSE}
img_path <- "data/train/crack/img_1_1_1345.png"
img <- image_load(img_path, target_size = c(224,224))
x <- image_to_array(img)
x <- x/255
dim(x) <- c(1, dim(x))
preds <- model %>% predict(x)
print("class probabilities(crack/no crack): "preds
```

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


Test model
========================================================

&nbsp;

```{r}
library(EBImage)
img <- readImage("data/train/crack/img_1_1_1345.png")
display(img)
```

```{r}
img_path <- "data/train/crack/img_1_1_1345.png"
img <- image_load(img_path, target_size = c(224,224))
x <- image_to_array(img)
x <- x/255
dim(x) <- c(1, dim(x))
preds <- model %>% predict(x)
preds
```

<div class="banner">
<img src='tri_logo_high.jpg' border=0 width='200px'>
</div>

<div class="footer">
<img src='cube3.png' border=0 width='122px'>
</div>


